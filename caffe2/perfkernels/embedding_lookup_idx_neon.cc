//// --------------------------
//// ATTENTION:
//// THIS CODE IS AUTOGENERATED
//// BY hp_emblookup_codegen.py
//// DO NOT MODIFY!!!
//// --------------------------

#include <c10/util/Half.h>
#include <c10/util/BFloat16.h>
#include <cmath>
#include "arm_neon.h"
namespace caffe2 {

template <bool IS_WEIGHT_POSITIONAL>
static bool EmbeddingLookupIdx_int64_t_float_float__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const float* input,
    const int64_t* indices,
    const int64_t* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
return true;
      	const int64_t prefdist_T0 = 16;
  // NOLINTNEXTLINE(cppcoreguidelines-narrowing-conversions,bugprone-narrowing-conversions)
  const int64_t fused_block_size = block_size + 0;
  int64_t dataInd = 0;
  if (block_size == 128) {
    // unrolling 16 times
  } else if (block_size == 64) {
    // unrolling 8 times
  } else if (block_size == 32) {
    // unrolling 4 times
  } else if (block_size == 16) {
    // unrolling 2 times
  } else {
    // generic code
    // NOLINTNEXTLINE(modernize-avoid-c-arrays,cppcoreguidelines-avoid-magic-numbers,cppcoreguidelines-avoid-c-arrays)
    for (int64_t rangeIndex = 0; rangeIndex < output_size; ++rangeIndex) {
      float* op = &out[rangeIndex * block_size];
      int64_t j = 0;
      float32x4_t ZeroFloat32x4 = vdupq_n_f32(0.0f);

      for (; j + 4 <= block_size; j += 4) {
        vst1q_f32(op + j, ZeroFloat32x4);
      }
      for (; j < block_size; j++) {
        op[j] = 0.0f;
      }
      if (dataInd != offsets[rangeIndex] - offsets[0]) {
        return false;
      }
      int64_t end_offset = offsets[rangeIndex + 1];
      int64_t length = end_offset - offsets[rangeIndex];
      for (int64_t start = dataInd; dataInd < end_offset - offsets[0];
           ++dataInd) {
        const int64_t idx = indices[dataInd];
        if (idx < 0 || idx >= data_size) {
          return false;
        }
        float wgt = 1.f;
        if (weights) {
          wgt = weights[IS_WEIGHT_POSITIONAL ? (dataInd - start) : dataInd];
        }
        float32x4_t vwgt = vdupq_n_f32(wgt);
        const float* ip = &input[idx * fused_block_size];
        const int64_t next_T0 = (dataInd < index_size - prefdist_T0)
            // NOLINTNEXTLINE(cppcoreguidelines-narrowing-conversions,bugprone-narrowing-conversions)
            ? (dataInd + prefdist_T0)
            // NOLINTNEXTLINE(cppcoreguidelines-narrowing-conversions,bugprone-narrowing-conversions)
            : dataInd;
        const int64_t idx_pref_T0 = indices[next_T0];
        if (idx_pref_T0 < 0 || idx_pref_T0 >= data_size) {
          return false;
        }
        const float* ip_next_T0 = &input[idx_pref_T0 * fused_block_size];
        j = 0;
        for (; j + 4 <= block_size; j += 4) {
          vst1q_f32(
              &op[j],
	       vfmaq_f32(
                  vwgt, vld1q_f32(&ip[j]), vld1q_f32(&op[j])));
#ifdef __GNUC__
          __builtin_prefetch(reinterpret_cast<const char*>(&ip_next_T0[j]), 0, 1);
#endif // __GNUC__

#if 0
          _mm256_storeu_ps(
              &op[j],
              _mm256_fmadd_ps(
                  vwgt, _mm256_loadu_ps(&ip[j]), _mm256_loadu_ps(&op[j])));
          _mm_prefetch(
              reinterpret_cast<const char*>(&ip_next_T0[j]), _MM_HINT_T0);
#endif
	}
        for (; j < block_size; j++) {
          op[j] = std::fma(wgt, ip[j], op[j]);
        }
      }
      if (normalize_by_lengths && length) {
        float len_inv = 1.0f / length;

        float32x4_t vlen_inv = vdupq_n_f32(len_inv);
        j = 0;
        for (; j + 4 <= block_size; j += 4) {

          vst1q_f32(
              &op[j], vmulq_f32(vld1q_f32(&op[j]), vlen_inv));		  
#if 0
          _mm256_storeu_ps(
              &op[j], _mm256_mul_ps(_mm256_loadu_ps(&op[j]), vlen_inv));
#endif
	}
        for (; j < block_size; j++) {
          op[j] = len_inv * op[j];
        }
      }
    }
  }
  return dataInd == index_size;
}
bool EmbeddingLookupIdx_int64_t_float_float_false__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const float* input,
    const int64_t* indices,
    const int64_t* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
  return EmbeddingLookupIdx_int64_t_float_float__neon_fma<false>(
      block_size,
      output_size,
      index_size,
      data_size,
      input,
      indices,
      offsets,
      weights,
      scale_bias,
      normalize_by_lengths,
      out);
}
bool EmbeddingLookupIdx_int64_t_float_float_true__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const float* input,
    const int64_t* indices,
    const int64_t* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
  return EmbeddingLookupIdx_int64_t_float_float__neon_fma<true>(
      block_size,
      output_size,
      index_size,
      data_size,
      input,
      indices,
      offsets,
      weights,
      scale_bias,
      normalize_by_lengths,
      out);
}

template <bool IS_WEIGHT_POSITIONAL>
static bool EmbeddingLookupIdx_int32_t_float_float__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const float* input,
    const int* indices,
    const int* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
	return false;
}

bool EmbeddingLookupIdx_int32_t_float_float_false__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const float* input,
    const int* indices,
    const int* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
  return EmbeddingLookupIdx_int32_t_float_float__neon_fma<false>(
      block_size,
      output_size,
      index_size,
      data_size,
      input,
      indices,
      offsets,
      weights,
      scale_bias,
      normalize_by_lengths,
      out);
}
bool EmbeddingLookupIdx_int32_t_float_float_true__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const float* input,
    const int* indices,
    const int* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
  return EmbeddingLookupIdx_int32_t_float_float__neon_fma<true>(
      block_size,
      output_size,
      index_size,
      data_size,
      input,
      indices,
      offsets,
      weights,
      scale_bias,
      normalize_by_lengths,
      out);
}

template <bool IS_WEIGHT_POSITIONAL>
static bool EmbeddingLookupIdx_int32_t_half_float__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const at::Half* input,
    const int* indices,
    const int* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
	return false;
}

bool EmbeddingLookupIdx_int32_t_half_float_false__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const at::Half* input,
    const int* indices,
    const int* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
  return EmbeddingLookupIdx_int32_t_half_float__neon_fma<false>(
      block_size,
      output_size,
      index_size,
      data_size,
      input,
      indices,
      offsets,
      weights,
      scale_bias,
      normalize_by_lengths,
      out);
}
bool EmbeddingLookupIdx_int32_t_half_float_true__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const at::Half* input,
    const int* indices,
    const int* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
  return EmbeddingLookupIdx_int32_t_half_float__neon_fma<true>(
      block_size,
      output_size,
      index_size,
      data_size,
      input,
      indices,
      offsets,
      weights,
      scale_bias,
      normalize_by_lengths,
      out);
}

template <bool IS_WEIGHT_POSITIONAL>
static bool EmbeddingLookupIdx_int64_t_half_float__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const at::Half* input,
    const int64_t* indices,
    const int64_t* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
return false;
}

bool EmbeddingLookupIdx_int64_t_half_float_false__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const at::Half* input,
    const int64_t* indices,
    const int64_t* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
  return EmbeddingLookupIdx_int64_t_half_float__neon_fma<false>(
      block_size,
      output_size,
      index_size,
      data_size,
      input,
      indices,
      offsets,
      weights,
      scale_bias,
      normalize_by_lengths,
      out);
}
bool EmbeddingLookupIdx_int64_t_half_float_true__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const at::Half* input,
    const int64_t* indices,
    const int64_t* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
  return EmbeddingLookupIdx_int64_t_half_float__neon_fma<true>(
      block_size,
      output_size,
      index_size,
      data_size,
      input,
      indices,
      offsets,
      weights,
      scale_bias,
      normalize_by_lengths,
      out);
}

template <bool IS_WEIGHT_POSITIONAL>
static bool EmbeddingLookupIdx_int32_t_bfloat16_float__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const at::BFloat16* input,
    const int* indices,
    const int* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
	return false;
}

bool EmbeddingLookupIdx_int32_t_bfloat16_float_false__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const at::BFloat16* input,
    const int* indices,
    const int* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
  return EmbeddingLookupIdx_int32_t_bfloat16_float__neon_fma<false>(
      block_size,
      output_size,
      index_size,
      data_size,
      input,
      indices,
      offsets,
      weights,
      scale_bias,
      normalize_by_lengths,
      out);
}
bool EmbeddingLookupIdx_int32_t_bfloat16_float_true__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const at::BFloat16* input,
    const int* indices,
    const int* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
  return EmbeddingLookupIdx_int32_t_bfloat16_float__neon_fma<true>(
      block_size,
      output_size,
      index_size,
      data_size,
      input,
      indices,
      offsets,
      weights,
      scale_bias,
      normalize_by_lengths,
      out);
}

template <bool IS_WEIGHT_POSITIONAL>
static bool EmbeddingLookupIdx_int64_t_bfloat16_float__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const at::BFloat16* input,
    const int64_t* indices,
    const int64_t* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
	return false;
}

bool EmbeddingLookupIdx_int64_t_bfloat16_float_false__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const at::BFloat16* input,
    const int64_t* indices,
    const int64_t* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
  return EmbeddingLookupIdx_int64_t_bfloat16_float__neon_fma<false>(
      block_size,
      output_size,
      index_size,
      data_size,
      input,
      indices,
      offsets,
      weights,
      scale_bias,
      normalize_by_lengths,
      out);
}
bool EmbeddingLookupIdx_int64_t_bfloat16_float_true__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const at::BFloat16* input,
    const int64_t* indices,
    const int64_t* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
  return EmbeddingLookupIdx_int64_t_bfloat16_float__neon_fma<true>(
      block_size,
      output_size,
      index_size,
      data_size,
      input,
      indices,
      offsets,
      weights,
      scale_bias,
      normalize_by_lengths,
      out);
}

template <bool IS_WEIGHT_POSITIONAL>
static bool EmbeddingLookupIdx_int32_t_uint8_t_float__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const uint8_t* input,
    const int* indices,
    const int* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
return false;
}

bool EmbeddingLookupIdx_int32_t_uint8_t_float_false__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const uint8_t* input,
    const int* indices,
    const int* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
  return EmbeddingLookupIdx_int32_t_uint8_t_float__neon_fma<false>(
      block_size,
      output_size,
      index_size,
      data_size,
      input,
      indices,
      offsets,
      weights,
      scale_bias,
      normalize_by_lengths,
      out);
}
bool EmbeddingLookupIdx_int32_t_uint8_t_float_true__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const uint8_t* input,
    const int* indices,
    const int* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
  return EmbeddingLookupIdx_int32_t_uint8_t_float__neon_fma<true>(
      block_size,
      output_size,
      index_size,
      data_size,
      input,
      indices,
      offsets,
      weights,
      scale_bias,
      normalize_by_lengths,
      out);
}

template <bool IS_WEIGHT_POSITIONAL>
static bool EmbeddingLookupIdx_int64_t_uint8_t_float__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const uint8_t* input,
    const int64_t* indices,
    const int64_t* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
	return false;
}

bool EmbeddingLookupIdx_int64_t_uint8_t_float_false__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const uint8_t* input,
    const int64_t* indices,
    const int64_t* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
  return EmbeddingLookupIdx_int64_t_uint8_t_float__neon_fma<false>(
      block_size,
      output_size,
      index_size,
      data_size,
      input,
      indices,
      offsets,
      weights,
      scale_bias,
      normalize_by_lengths,
      out);
}
bool EmbeddingLookupIdx_int64_t_uint8_t_float_true__neon_fma(
    const int64_t block_size,
    const int64_t output_size,
    const int64_t index_size,
    const int64_t data_size,
    const uint8_t* input,
    const int64_t* indices,
    const int64_t* offsets,
    const float* weights,
    const float* scale_bias,
    bool normalize_by_lengths,
    float* out) {
  return EmbeddingLookupIdx_int64_t_uint8_t_float__neon_fma<true>(
      block_size,
      output_size,
      index_size,
      data_size,
      input,
      indices,
      offsets,
      weights,
      scale_bias,
      normalize_by_lengths,
      out);
}

} // namespace caffe2

